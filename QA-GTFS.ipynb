{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "GTFS Wiki: http://wiki.corp.nextbus.com/nextbuswiki/GtfsChecks (need to be on NexBus VPN) \n",
    "\n",
    "GTFS Goolge Guideline: https://developers.google.com/transit/gtfs/reference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Import the needed packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pixiedust as pix # will look into the capabilites of this library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Add the location of your GTFS data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for windows\n",
    "# filepath = r\"\\\\cts-con-fld-001\\users$\\207329\\My Documents\\qa\\vacaville\\vacavillecitycoach-ca-us_20181015\"\n",
    "\n",
    "# for linux\n",
    "filepath = r\"/mnt/shared/qa/foothill\"\n",
    "\n",
    "# filepath2 = r\"/mnt/shared/qa/seattle-sc/Seattle-sc-ALL_20181126_google_daily_transit\"\n",
    "\n",
    "\n",
    "\n",
    "'''Some functions to make life eaiser\n",
    "Note if you are using Windows, you'll need to modify the \"/\" '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load file and show top 5 records\n",
    "def load(fName): \n",
    "    f = filepath + \"/\" + \"{}.txt\".format(fName)\n",
    "    global df\n",
    "    df = pd.read_csv(f)\n",
    "    return df.info()\n",
    "\n",
    "# load second file for comparision\n",
    "def load2(fName): \n",
    "    f = filepath2 + \"/\" + \"{}.txt\".format(fName)\n",
    "    global df2\n",
    "    df2 = pd.read_csv(f)\n",
    "    return df2.info()\n",
    "\n",
    "import csv\n",
    "# short save file\n",
    "def save(dfName,fName):\n",
    "    df = dfName\n",
    "    df.to_csv(filepath + '//' + \"{}\".format(fName), sep =',', index=False)#, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    return print(\"Saved {} to {}\".format(fName,filepath))\n",
    "\n",
    "# short find null\n",
    "def null(fName):\n",
    "    return df[(fName).isnull()]\n",
    "\n",
    "# drop field (field name, file name)\n",
    "def drop(fName,fileName):\n",
    "    df.drop(fName, 1, inplace=True)\n",
    "    df.to_csv(filepath + '//' + '{}_FIXED.txt'.format(fileName), sep =',', index=False)\n",
    "    return print(\"Dropped {} field.\\n\\\n",
    "Saved '{}_FIXED.txt' to file folder.\".format(fName,fileName))\n",
    "\n",
    "# drop dups in blocks.txt for CNB \n",
    "def dups():\n",
    "    #df[df.block_id.duplicated()]\n",
    "    df1 = df.drop_duplicates(subset = 'block_id', keep='last').reset_index(drop=True)\n",
    "    return df1.info()\n",
    "    \n",
    "# sort sequence for stop_times.txt file\n",
    "def sort():\n",
    "    df.sort_values(['trip_id', 'stop_sequence'])\n",
    "    return df.head(15)\n",
    "\n",
    "# shape less than certain amount of points for shapes\n",
    "def lessthan(x):\n",
    "    df1 = df.groupby(['shape_id']).count()\n",
    "    return df1[(df1.shape_pt_lat < x)]\n",
    "\n",
    "# function to move copy stop_code to stop_id in the stops.txt file\n",
    "def copyField(newField,origField,fileName):\n",
    "    df[newField] = df[origField]\n",
    "    df.to_csv(filepath + '//' + '{}_FIXED.txt'.format(fileName), sep =',', index=False)\n",
    "    return print(\"Copied the '{}' field to the '{}' field.\\n\\\n",
    "Saved '{}_FIXED.txt' to file folder.\".format(origField,newField,fileName))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### work for CNB shape issues\n",
    "# def shapeFix(indx1,indx2,shapeName):\n",
    "#     x1 = int(indx1)\n",
    "#     x2 = int(indx2)\n",
    "#     global df\n",
    "#     df = df.drop(df.index[x1:x2]) # drop double shape pnts \n",
    "#     df = df[(df.shape_id == '{}'.format(shapeName))] # create new df of just shape pnts\n",
    "#     df['shape_pt_sequence'] = range(1,1 + len(df)) # re-sequence shape pnts\n",
    "#     df_cut = df # give unique name to subset of shape pnts\n",
    "\n",
    "#     # load orig data, drop all of courthou1, append \n",
    "#     load('shapes') # load orig df\n",
    "#     df = df[df.shape_id != '{}'.format(shapeName)] # drop all cases of shape \n",
    "#     global df_all\n",
    "#     df_all = df.append(df_cut,ignore_index=True) # create new df and append df_cut\n",
    "#     return  print('use df_all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Work-flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill na with number, query and output file  \n",
    "df['block_id'].fillna(999999, inplace=True)\n",
    "df1 = df[(df.block_id == 999999)]\n",
    "df['block_id'].unique()\n",
    "save(df1,'trips_missingBlocks.txt')\n",
    "\n",
    "# compare two files\n",
    "# set the field to a list\n",
    "oldTrips = df2['trip_id'].unique().tolist()\n",
    "newTrips = df['trip_id'].unique().tolist()\n",
    "\n",
    "oldBlocks = df2['block_id'].unique().tolist()\n",
    "newBlocks = df['block_id'].unique().tolist()\n",
    "\n",
    "# use set and difference to compare the two list\n",
    "set(oldTrips).difference(newTrips)\n",
    "\n",
    "set(newBlocks).difference(oldBlocks)\n",
    "\n",
    "# can alsow use this logic... but the above works just fine\n",
    "if (40803723 in newTrips):\n",
    "    print (\"Exist\")\n",
    "else:\n",
    "    print(\"Nope\")\n",
    "\n",
    "##### seattle-sc 'like' function \n",
    "df=df.loc[df['route_id'].isin([100340,102638])]\n",
    "df\n",
    "save(df,'trips')\n",
    "df['service_id'].unique()\n",
    "df2=df2.loc[df2['route_id'].isin([100340,102638])]\n",
    "\n",
    "#### create new column based on conditions of other columns\n",
    "df['timeCheck'] = np.where(df['arrival_time']==df['departure_time'],'yes','no')\n",
    "df1 = df[(df.timeCheck=='no')]\n",
    "df['timeCheck'].unique()\n",
    "\n",
    "# syntax for leading zeros (4 for example)\n",
    "df['stop_id']= df['stop_id'].apply(lambda x: '{0:0>4}'.format(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">agency.txt</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 5 columns):\n",
      "agency_name        1 non-null object\n",
      "agency_url         1 non-null object\n",
      "agency_timezone    1 non-null object\n",
      "agency_lang        0 non-null float64\n",
      "agency_phone       1 non-null object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 120.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "load('agency')\n",
    "# df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">routes.txt</span>\n",
    "\n",
    "### Required Fields: \n",
    "1. route_id- These are the routes that are shown to the public. Route ID's cannot have leading zeros, asterisks, underscore, dashes and perhaps other characters. \n",
    "2. route_type- numberic value with specific meanings:\n",
    "    * 0 Tram, Streetcar, Light rail\n",
    "    * 1 Subway, Metro\n",
    "    * 2 Rail\n",
    "    * 3 Bus\n",
    "    * 4 Ferry\n",
    "    * 5 Cable Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39 entries, 0 to 38\n",
      "Data columns (total 8 columns):\n",
      "route_id            39 non-null object\n",
      "route_short_name    39 non-null object\n",
      "route_long_name     39 non-null object\n",
      "route_desc          0 non-null float64\n",
      "route_type          39 non-null int64\n",
      "route_url           39 non-null object\n",
      "route_color         0 non-null float64\n",
      "route_text_color    0 non-null float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# just use the funtion 'load()' to load the .txt file and see the first 5 lines ex: loadfile('routes')\n",
    "load('routes')\n",
    "# df.head(100)\n",
    "#copyField('route_short_name','route_id','routes')\n",
    "# dfEOS = df[(df.agency_id == 'EOS')]\n",
    "# save(dfEOS,'routes')\n",
    "\n",
    "#### seattle-sc 'like' function\n",
    "#df = df.loc[df['agency_id']=='EOS']\n",
    "# df1['route_long_name'] = df1['route_short_name']\n",
    "# df = df1\n",
    "# save('routes_NEW.txt')\n",
    "#df[(df.route_id==100249)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">trips.txt</span>\n",
    "\n",
    "### Required Fields:\n",
    "1. route_id- Check to see if there are trips for every route. \n",
    "2. service_id- Check to see if the value of this field comes from the calendar.txt file. (below)\n",
    "3. trip_id\n",
    "4. direction_id- Can either be 1 or 0. Can omit if all routes are in one direction. \n",
    "5. block_id- GTFS list this as optional, NextBus requires it. Make sure there are no missig values. \n",
    "6. shape_id- GTFS list this as optional, NextBus requires it. This field links with the shapes.txt file.(below)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4579 entries, 0 to 4578\n",
      "Data columns (total 7 columns):\n",
      "route_id         4579 non-null object\n",
      "service_id       4579 non-null object\n",
      "trip_id          4579 non-null object\n",
      "trip_headsign    4579 non-null object\n",
      "direction_id     4579 non-null int64\n",
      "block_id         4579 non-null int64\n",
      "shape_id         4579 non-null int64\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 250.5+ KB\n"
     ]
    }
   ],
   "source": [
    "load('trips')\n",
    "# df.head()\n",
    "\n",
    "\n",
    "# dffoo = df[(df.block_id == 5254117)]\n",
    "# dffoo.head()\n",
    "\n",
    "## dups work\n",
    "#df[df.block_id.duplicated()]\n",
    "#df1 = df.drop_duplicates(subset = 'block_id', keep='last').reset_index(drop=True)\n",
    "#102638\n",
    "\n",
    "# df1 = df[(df.route_id == '860-150') | (df.route_id == '861-150')]\n",
    "# df1 = df[(df.trip_headsign == 'Not In Service')]\n",
    "# df1\n",
    "# save(df1,'foothill_trips_notInService.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">stops.txt</span>\n",
    "\n",
    "### Required Fields:\n",
    "1. stop_id \n",
    "2. stop_lat- Make sure none are zero, or empty.\n",
    "3. stop_lon- Make sure none are zero, or empty.\n",
    "    - make sure lat and long are at least five decimal places (most do six) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1971 entries, 0 to 1970\n",
      "Data columns (total 10 columns):\n",
      "stop_id           1971 non-null object\n",
      "stop_code         0 non-null float64\n",
      "stop_name         1971 non-null object\n",
      "stop_desc         0 non-null float64\n",
      "stop_lat          1971 non-null float64\n",
      "stop_lon          1971 non-null float64\n",
      "zone_id           0 non-null float64\n",
      "stop_url          0 non-null float64\n",
      "location_type     1971 non-null int64\n",
      "parent_station    8 non-null object\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 154.1+ KB\n"
     ]
    }
   ],
   "source": [
    "load('stops')\n",
    "# df.head(25)\n",
    "\n",
    "# copyField('stop_code','stop_id','stops')\n",
    "\n",
    "#### seattle-sc 'like' function\n",
    "#df_stop = df.loc[df['stop_code'].isin(stopList)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">stop_times.txt</span>\n",
    "\n",
    "### Required Fields:\n",
    "1. trip_id\n",
    "2. arrival_time- Should be blank for non-scheduled stops\n",
    "3. depature_times- Should be blank for non-scheduled stops\n",
    "4. stop_id\n",
    "5. stop_sequence- Some agencies will sort this field incorrectly, putting all the \"1s\" first.\n",
    "    - note* watch out for the timepoints field, if there is a 1, then it is an acutal stop. If there are not enough of 1s, this may cause problems. It's okay to delete this field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188235 entries, 0 to 188234\n",
      "Data columns (total 9 columns):\n",
      "trip_id                188235 non-null object\n",
      "arrival_time           188235 non-null object\n",
      "departure_time         188235 non-null object\n",
      "stop_id                188235 non-null int64\n",
      "stop_sequence          188235 non-null int64\n",
      "pickup_type            188235 non-null int64\n",
      "drop_off_type          188235 non-null int64\n",
      "shape_dist_traveled    188235 non-null float64\n",
      "timepoint              188235 non-null int64\n",
      "dtypes: float64(1), int64(5), object(3)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "source": [
    "load('stop_times') \n",
    "# df.head(25)\n",
    "\n",
    "#drop('timepoint','stop_times')\n",
    "# df.head(100)\n",
    "# syntax for leading zeros (4 for example)\n",
    "# df['stop_id']= df['stop_id'].apply(lambda x: '{0:0>4}'.format(x))\n",
    "# df.head(100)\n",
    "# df['timepoint'].unique()\n",
    "\n",
    "# df[(df.arrival_time!=null) & (df.timepoint==1)]\n",
    "# df[(df.trip_id == 't_31175_b_718_tn_0')]\n",
    "\n",
    "# drop('timepoint','stop_times')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### seattle-sc 'like' function\n",
    "# df_trip = df.loc[df['trip_id'].isin(tripsList)]\n",
    "# df_trip.sort_values(['trip_id', 'stop_sequence'])\n",
    "# stopList = df_trip['stop_id'].unique().tolist()\n",
    "# save(df_trip,'stop_times_NEW.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">shapes.txt</span>\n",
    "\n",
    "### Required Fields:\n",
    "1. shape_id\n",
    "2. shape_pnt_lat- at least five decimal places\n",
    "3. shape_pnt_lon- at least five deciaml places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76108 entries, 0 to 76107\n",
      "Data columns (total 5 columns):\n",
      "shape_id               76108 non-null int64\n",
      "shape_pt_lat           76108 non-null float64\n",
      "shape_pt_lon           76108 non-null float64\n",
      "shape_pt_sequence      76108 non-null int64\n",
      "shape_dist_traveled    76108 non-null float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "load('shapes')\n",
    "# df.head(50)\n",
    "\n",
    "# lessthan(100)\n",
    "\n",
    "\n",
    "# df['shape_pt_sequence'] = df['shape_pt_sequence'].astype(np.int64)\n",
    "# save(df,'shapesINT.txt')\n",
    "# df1 = df[(df.shape_id=='J_trip_inbound_pm')]\n",
    "# save(df1,'J_trip_inbound_pm.csv')\n",
    "\n",
    "# flip the point sequence \n",
    "# df2 = df[(df.shape_id == 'J_trip_inbound_am')]\n",
    "# drop = df2[::-1].drop(columns=['shape_pt_sequence'])\n",
    "# drop.loc[:,'shape_pt_sequence'] = range(1, 1 + len(drop))\n",
    "# # drop\n",
    "\n",
    "# df3 = df[df.shape_id != 'J_trip_inbound_am']\n",
    "# df4 = df3.append(drop)\n",
    "# new = df4[(df4.shape_id == 'J_trip_inbound_am')]\n",
    "# df4\n",
    "# save(df4,'shapes_NEW.txt')\n",
    "# dfJ = df[(df['shape_id'].str.contains('J'))]\n",
    "# dfJ['shape_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">calendar.txt</span>\n",
    "\n",
    "### Required:\n",
    "Run the calendar script if more than one service record is defined for the day of the week.\n",
    "* If there is more than one service defined for the week, then run the calendar.py script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 10 columns):\n",
      "service_id    8 non-null object\n",
      "monday        8 non-null int64\n",
      "tuesday       8 non-null int64\n",
      "wednesday     8 non-null int64\n",
      "thursday      8 non-null int64\n",
      "friday        8 non-null int64\n",
      "saturday      8 non-null int64\n",
      "sunday        8 non-null int64\n",
      "start_date    8 non-null int64\n",
      "end_date      8 non-null int64\n",
      "dtypes: int64(9), object(1)\n",
      "memory usage: 720.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "load('calendar')\n",
    "# df.head(35)\n",
    "\n",
    "\n",
    "#### seattle-sc 'like' function\n",
    "# df_cal = df.loc[df['service_id'].isin(serviceList)]\n",
    "# df_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">calendar_dates.txt</span>\n",
    "\n",
    "### Required:\n",
    "This is an optional file, but is used to mark special holidays. Make sure the dates make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 3 columns):\n",
      "service_id        12 non-null object\n",
      "date              12 non-null int64\n",
      "exception_type    12 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 368.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "load('calendar_dates')\n",
    "# df.head(50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
