{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial.distance import cdist\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22 entries, 0 to 21\n",
      "Data columns (total 9 columns):\n",
      "route_id            22 non-null int64\n",
      "agency_id           22 non-null int64\n",
      "route_short_name    22 non-null object\n",
      "route_long_name     22 non-null object\n",
      "route_desc          0 non-null float64\n",
      "route_type          22 non-null int64\n",
      "route_url           22 non-null object\n",
      "route_color         22 non-null object\n",
      "route_text_color    22 non-null object\n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Load and save functions.'''\n",
    "\n",
    "filepath = r'scripts/bbb-new'\n",
    "\n",
    "# load file\n",
    "def load(fName): \n",
    "    f = filepath + \"/\" + \"{}.txt\".format(fName)\n",
    "    return pd.read_csv(f)\n",
    "\n",
    "# save file\n",
    "def save(dfName,fName):\n",
    "    df = dfName\n",
    "    df.to_csv(filepath + '/' + \"{}_NEW.txt\".format(fName), sep =',', index=False, float_format=\"%.6f\")\n",
    "    return print(\"Saved {}_NEW.txt to {}\".format(fName,filepath))\n",
    "\n",
    "# load GTFS files\n",
    "trips = load('trips')\n",
    "stops = load('stops')\n",
    "stop_times = load('stop_times')\n",
    "shapes = load('shapes')\n",
    "routes = load('routes')\n",
    "routes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence',\n",
       "       'stop_headsign', 'pickup_type', 'drop_off_type', 'shape_dist_traveled',\n",
       "       'timepoint', 'stop_code', 'stop_name', 'stop_desc', 'stop_lat',\n",
       "       'stop_lon', 'zone_id', 'stop_url', 'location_type', 'parent_station',\n",
       "       'stop_timezone', 'wheelchair_boarding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''USED FOR TESTING- query a single trip, shape, stops'''\n",
    "# get one trip to test \n",
    "# onetrip = trips[(trips.trip_id == 782006)]\n",
    "# oneshape = shapes[(shapes.shape_id == 23897)]\n",
    "# stopTimeStops = stop_times['stop_id'][(stop_times.trip_id == 782006)].tolist()\n",
    "# # stopTimeStops = (stop_times.trip_id == 782006).tolist()\n",
    "# neededStops = stops[stops['stop_id'].isin(stopTimeStops)]\n",
    "# lstlat = neededStops['stop_lat'].tolist()\n",
    "# lstlon = neededStops['stop_lon'].tolist()\n",
    "# stpCoord = np.array(list(zip(lstlat,lstlon)))\n",
    "# stopcoordslst = list(result)\n",
    "# stopsNstop_times.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_times.info()\n",
    "'''Need to create a massive DF with the stop_times, shape_ids, stops. Then the distance function and the rest of the script'''\n",
    "\n",
    "# join shapes and trips\n",
    "# seems like there are more than one trip per shape... how can this be joined w/o creatng a huge df \n",
    "shapesNtrips = pd.merge(shapes,trips,how='left',on='shape_id',suffixes=('','_trip'))\n",
    "shapesNtrips = shapesNtrips.drop(['shape_dist_traveled', 'service_id','trip_headsign', 'trip_short_name', 'direction_id', 'block_id','wheelchair_accessible', 'bikes_allowed','block_id'],axis=1)\n",
    "shapesNtripsSorted = shapesNtrips.sort_values(['trip_id','shape_pt_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1051645 entries, 629 to 1050108\n",
      "Data columns (total 6 columns):\n",
      "shape_id             1051645 non-null int64\n",
      "shape_pt_lat         1051645 non-null float64\n",
      "shape_pt_lon         1051645 non-null float64\n",
      "shape_pt_sequence    1051645 non-null int64\n",
      "route_id             1051645 non-null int64\n",
      "trip_id              1051645 non-null int64\n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 56.2 MB\n"
     ]
    }
   ],
   "source": [
    "shapesNtripsSorted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join stop lat longs to stop_times\n",
    "stopsNstop_times = pd.merge(stop_times,stops,how='left',on='stop_id')\n",
    "stopsNstop_times = stopsNstop_times.drop(['arrival_time', 'departure_time','stop_headsign', 'pickup_type', 'drop_off_type', 'shape_dist_traveled', 'timepoint', \\\n",
    "                        'stop_code', 'stop_name', 'stop_desc', 'zone_id', 'stop_url', 'location_type', 'parent_station','stop_timezone', 'wheelchair_boarding'],axis=1)\n",
    "stopsNstop_timesSorted = stopsNstop_times.sort_values(['trip_id','stop_sequence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subStopTimes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 20 to 872\n",
      "Data columns (total 12 columns):\n",
      "stop_id                30 non-null int64\n",
      "stop_code              30 non-null int64\n",
      "stop_name              30 non-null object\n",
      "stop_desc              30 non-null object\n",
      "stop_lat               30 non-null float64\n",
      "stop_lon               30 non-null float64\n",
      "zone_id                0 non-null float64\n",
      "stop_url               0 non-null float64\n",
      "location_type          0 non-null float64\n",
      "parent_station         0 non-null float64\n",
      "stop_timezone          0 non-null float64\n",
      "wheelchair_boarding    30 non-null int64\n",
      "dtypes: float64(7), int64(3), object(2)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "'''have the input accept one route'''\n",
    "# singleRouteId = sys.argv[0]\n",
    "# singleRouteId = routes.route_id == 3025\n",
    "singleRoute = trips.route_id == 3025\n",
    "\n",
    "subShapeList = trips[singleRoute].shape_id.unique().tolist()\n",
    "subShapes = shapes[shapes.shape_id.isin(subShapeList)]\n",
    "\n",
    "subTripsList = trips[singleRoute].trip_id.unique().tolist()\n",
    "subTrips = trips[trips.trip_id.isin(subTripsList)]\n",
    "\n",
    "subStopTimesList = stop_times.stop_id[stop_times.trip_id.isin(subTripsList)].tolist()\n",
    "\n",
    "subStops = stops[stops.stop_id.isin(subStopTimesList)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 135 entries, 19511 to 19645\n",
      "Data columns (total 5 columns):\n",
      "shape_id               135 non-null int64\n",
      "shape_pt_lat           135 non-null float64\n",
      "shape_pt_lon           135 non-null float64\n",
      "shape_pt_sequence      135 non-null int64\n",
      "shape_dist_traveled    135 non-null float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 6.3 KB\n"
     ]
    }
   ],
   "source": [
    "subShapes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWEET! You modified 35 shape points.\n",
      "\n",
      "Saved shapes_FIXED.txt to scripts/bbb-new\n"
     ]
    }
   ],
   "source": [
    "'''MAIN WORK HERE'''\n",
    "\n",
    "# turn stops coords to list, then numpy array\n",
    "# this will be used for the distance function\n",
    "stpLat = subStops.stop_lat.tolist()\n",
    "stpLon = subStops.stop_lon.tolist()\n",
    "stpCoord = np.array(list(zip(stpLat,stpLon)))\n",
    "\n",
    "# turn shape coords to list, then turn to numpy array\n",
    "# this will be used for the distance function\n",
    "shpLat = subShapes.shape_pt_lat.tolist()\n",
    "shpLon = subShapes.shape_pt_lon.tolist()\n",
    "shpCoord = np.array(list(zip(shpLat,shpLon)))\n",
    "\n",
    "# create a dataframe to use as a way to identify the rows that need to be changed \n",
    "# shapes = pd.DataFrame({\n",
    "#     'shape_id' : shapes.shape_id,\n",
    "#     'shape_pt_lat' : shapes.shape_pt_lat,\n",
    "#     'shape_pt_lon' : shapes.shape_pt_lon,\n",
    "#     'shape_pt_sequence' : shapes.shape_pt_sequence,\n",
    "#     'shape_dist_traveled' : shapes.shape_dist_traveled,\n",
    "#     # use the euclidean distance function here and multiply by 10000 to get some eaiser numbers to work with\n",
    "#     'dist_to_stp': cdist(shpCoord,stpCoord,'euclidean').min(axis=1) * 10000\n",
    "\n",
    "# })\n",
    "\n",
    "# shapes['dist_to_stp'] = cdist(shpCoord,stpCoord,'euclidean').min(axis=1) * 10000\n",
    "subShapes['dist_to_stp'] = cdist(shpCoord,stpCoord,'euclidean').min(axis=1) * 10000\n",
    "\n",
    "\n",
    "''''''\n",
    "\n",
    "# find difference between dist_to_stp rows\n",
    "subShapes['diff'] = subShapes['dist_to_stp'] - subShapes['dist_to_stp'].shift(1)\n",
    "# create a dummy column marking where the diff is negative\n",
    "subShapes['dummy'] = np.where(subShapes['diff'] < 0,'1','0')\n",
    "'''Keep where diff == NaN- this is first shape point and 'should' begin at a stop OR where distance to stop is < 2.8 OR where dummy == 1 AND the the value below it is == 0\n",
    "AND Keep where dummy == 1 AND distance to stop is < 5 (this may change). This logic will ensure the closest stop is grabbed based on criteria other than spatial criteria. \n",
    "The result is a column named \"keep\" with values of either keep or throw. These values are used later on with a buffer from the stop to highlight the rows to change'''\n",
    "subShapes['keep'] = np.where(np.logical_or(subShapes['diff'].isna(),\\\n",
    "                                                     np.logical_or(subShapes['dist_to_stp'] < 2.8,\\\n",
    "                                                                    np.logical_and(np.logical_and(subShapes['dummy'] == '1', subShapes['dist_to_stp'] < 5.),\\\n",
    "                                                                                   np.logical_and(subShapes['dummy'] == '1', subShapes['dummy'].shift(-1) == '0')\\\n",
    "                                                                                  )\\\n",
    "                                                                  )\\\n",
    "                                                    ) ,'keep','throw')\n",
    "\n",
    "\n",
    "'''With all of the other parameters above, have a column with a buffer of the stop and check to see if a shape point marked as \"keep\"\n",
    "falls within that buffer. If it does, update the shape point lat and lon for that row. There may be more than one shape point moved, inital testng \n",
    "has shown this not to be a problem. The generaliztion around the stops \"should\" not be noticeable. More testing should be done to 100% confirm'''\n",
    "\n",
    "# create a geodataframe to do an intersection \n",
    "intersect_df = gpd.GeoDataFrame(subShapes, geometry = gpd.points_from_xy(subShapes.shape_pt_lon,subShapes.shape_pt_lat))\n",
    "intersect_df['shape_pt_geometry'] = intersect_df['geometry']\n",
    "intersect_df.drop(['geometry'],axis=1)\n",
    "\n",
    "# stop dataframe with a buffer- distance can be adjusted if need be\n",
    "stopdf = gpd.GeoDataFrame(subStops, geometry=gpd.points_from_xy(subStops.stop_lon,subStops.stop_lat))\n",
    "stopdf['geometry'] = stopdf.geometry.buffer(.0005)\n",
    "\n",
    "# intersect df based on buffer polygon\n",
    "intersect_join = gpd.sjoin(intersect_df,stopdf,how='inner',op='intersects')\n",
    "# only keep the records 'keep'\n",
    "intersect_join = intersect_join[(intersect_join.keep == 'keep')]\n",
    "\n",
    "'''join the intersect df back to the nearest shape df based on index and create the new shapes.txt'''\n",
    "badMerge = pd.merge(subShapes,intersect_join,how='left',suffixes=('','_y'),left_index=True,right_index=True)\n",
    "# got a duplicated index somehow, drop it here\n",
    "finalMerge = badMerge[~badMerge.index.duplicated()]\n",
    "\n",
    "# update the new join shape lat lon with stop lat lon based on the 'keep' column\n",
    "finalMerge.loc[finalMerge['keep'] == 'keep', 'shape_pt_lat'] = finalMerge['stop_lat']\n",
    "finalMerge.loc[finalMerge['keep'] == 'keep', 'shape_pt_lon'] = finalMerge['stop_lon']\n",
    "\n",
    "# merge the lat lon \n",
    "finalMerge.round({'shape_pt_lat': 6, 'shape_pt_lon': 6})\n",
    "\n",
    "# drop unwanted columns from the final merge df to create the shapes_NEW.txt\n",
    "dropCols = [i for i in range(len(finalMerge.columns)) if i > 4]\n",
    "finalMerge.drop(finalMerge.columns[dropCols],axis=1,inplace=True)\n",
    "# finalMerge.info()\n",
    "\n",
    "#  print the amount of points that were changed\n",
    "changedPoints = finalMerge.shape_pt_lat != subShapes.shape_pt_lat\n",
    "print('SWEET! You modified {} shape points.\\n'.format(len(finalMerge[changedPoints])))\n",
    "\n",
    "# finalMerge.head()\n",
    "save(finalMerge,'shapes')\n",
    "# this is the final product- OLD WAY, keep this for testing\n",
    "# finalMerge[['shape_id','shape_pt_lat','shape_pt_lon', 'shape_pt_sequence']]\n",
    "# finalMerge.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20808 entries, 0 to 20807\n",
      "Data columns (total 5 columns):\n",
      "shape_id               20808 non-null int64\n",
      "shape_pt_lat           20808 non-null float64\n",
      "shape_pt_lon           20808 non-null float64\n",
      "shape_pt_sequence      20808 non-null int64\n",
      "shape_dist_traveled    20808 non-null float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "finalMerge.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Test graph to look at the distances of the shape points in comparison to stops along the route'''\n",
    "# plot the distance from the stop... the 'valleys' are where the stops are\n",
    "# plt.figure()\n",
    "# plt.ylabel(\"Distance From Stop\").set_color(\"White\")\n",
    "# nearest_shapePnt_df['dist_to_stp'].plot(kind='bar',figsize=(20,7)).axes.get_xaxis().set_visible(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Test map (graph) to look at ALL of the shape points for a route in comparison to stops along the route'''\n",
    "# plot the stops (red) and the shape points the script returns (blue)\n",
    "# all of the shape points FOR TESTING\n",
    "# allShapePoints = gpd.GeoDataFrame(oneshape, geometry=gpd.points_from_xy(oneshape.shape_pt_lon,oneshape.shape_pt_lat))\n",
    "# stopsTest = testStopdf.plot(figsize=(15,15),color='red', marker='o',markersize=150)\n",
    "# # allShapePoints.plot(figsize=(15,15),color='blue')\n",
    "# allShapePoints.plot(ax=stopsTest, color='blue',marker='o',markersize=20)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Test map (graph) to look at a subset of the shape points identifed as being nearest to stops along the route'''\n",
    "# # testPointsdf = gpd.GeoDataFrame(oneshape, geometry=gpd.points_from_xy(oneshape.shape_pt_lon,oneshape.shape_pt_lat))\n",
    "# testPointsdf = gpd.GeoDataFrame(keepPnts, geometry=gpd.points_from_xy(keepPnts.shape_pt_lon,keepPnts.shape_pt_lat))\n",
    "# testPointsdf\n",
    "# testStopdf = gpd.GeoDataFrame(neededStops, geometry=gpd.points_from_xy(neededStops.stop_lon,neededStops.stop_lat))\n",
    "# testStopdf['geometry'] = testStopdf.geometry.buffer(0.0010)\n",
    "# testStopdf\n",
    "#plot shape points and stops... see an extra shape point near southern part of route\n",
    "# testPointsdf = gpd.GeoDataFrame(keepPnts, geometry=gpd.points_from_xy(keepPnts.shape_pt_lon,keepPnts.shape_pt_lat))\n",
    "# newShapesGdf = gpd.GeoDataFrame(newShapesTxt, geometry=gpd.points_from_xy(newShapesTxt.shape_pt_lon,newShapesTxt.shape_pt_lat))\n",
    "# stopsTest = testStopdf.plot(figsize=(15,15),color='red',marker='o',markersize=150)\n",
    "# newShapesGdf.plot(ax=stopsTest, color='blue',marker='o',markersize=20)\n",
    "# plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
